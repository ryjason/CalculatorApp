{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "8ZGLh1C9eDfu",
        "outputId": "800e8d19-03df-43f6-f8a9-539961858c99",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn==1.5.2 in /usr/local/lib/python3.11/dist-packages (1.5.2)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.5.2) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.5.2) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.5.2) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.5.2) (3.5.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install scikit-learn==1.5.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "N-PFIGXx43nP"
      },
      "outputs": [],
      "source": [
        "# import pandas as pd\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# from sklearn.preprocessing import LabelEncoder\n",
        "# import xgboost as xgb\n",
        "\n",
        "# data = pd.read_csv('https://byui-cse.github.io/cse450-course/ice/wine/data/wine-training.csv')\n",
        "# X = data.drop(columns=['wine'])\n",
        "# y = data['wine']\n",
        "\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# xgb_model = xgb.XGBClassifier(\n",
        "#     objective='multi:softmax',\n",
        "#     num_class=3,\n",
        "#     n_estimators=500,\n",
        "#     learning_rate=0.05,\n",
        "#     max_depth=6,\n",
        "#     subsample=0.8,\n",
        "#     colsample_bytree=0.8,\n",
        "#     random_state=42\n",
        "# )\n",
        "\n",
        "# xgb_model.fit(X_train, y_train)\n",
        "\n",
        "# train_score = xgb_model.score(X_train, y_train)\n",
        "# test_score = xgb_model.score(X_test, y_test)\n",
        "\n",
        "# print(f\"Train Score: {train_score:.4f}\")\n",
        "# print(f\"Test Score: {test_score:.4f}\")\n",
        "\n",
        "# missing_values = data.isnull().sum()\n",
        "\n",
        "# wine_distribution = data['wine'].value_counts(normalize=True)\n",
        "\n",
        "# missing_values, wine_distribution"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import xgboost as xgb\n",
        "\n",
        "data = pd.read_csv('https://byui-cse.github.io/cse450-course/ice/wine/data/wine-training.csv')\n",
        "X = data.drop(columns=['wine'])\n",
        "y = data['wine']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
        "\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "dtrain = xgb.DMatrix(X_train_balanced, label=y_train_balanced)\n",
        "dtest = xgb.DMatrix(X_test, label=y_test)\n",
        "\n",
        "params = {\n",
        "    'objective': 'multi:softmax',\n",
        "    'num_class': 3,\n",
        "    'learning_rate': 0.05,\n",
        "    'max_depth': 6,\n",
        "    'subsample': 0.8,\n",
        "    'colsample_bytree': 0.8,\n",
        "    'random_state': 42,\n",
        "    'eval_metric': 'mlogloss'\n",
        "}\n",
        "\n",
        "evals = [(dtrain, 'train'), (dtest, 'eval')]\n",
        "model = xgb.train(\n",
        "    params,\n",
        "    dtrain,\n",
        "    num_boost_round=300,\n",
        "    evals=evals,\n",
        "    early_stopping_rounds=20,\n",
        "    verbose_eval=True\n",
        ")\n",
        "\n",
        "y_train_pred = model.predict(dtrain)\n",
        "y_test_pred = model.predict(dtest)\n",
        "\n",
        "train_score = accuracy_score(y_train_balanced, y_train_pred)\n",
        "test_score = accuracy_score(y_test, y_test_pred)\n",
        "\n",
        "train_f1 = f1_score(y_train_balanced, y_train_pred, average='weighted')\n",
        "test_f1 = f1_score(y_test, y_test_pred, average='weighted')\n",
        "conf_matrix = confusion_matrix(y_test, y_test_pred)\n",
        "class_report = classification_report(y_test, y_test_pred)\n",
        "\n",
        "print(f\"Train Accuracy: {train_score:.4f}\")\n",
        "print(f\"Test Accuracy: {test_score:.4f}\")\n",
        "print(f\"Train F1 Score: {train_f1:.4f}\")\n",
        "print(f\"Test F1 Score: {test_f1:.4f}\")\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "print(\"\\nClassification Report:\")\n",
        "print(class_report)\n"
      ],
      "metadata": {
        "id": "x3ReM2tdi0m3",
        "outputId": "8dfb29df-9fbe-4969-e031-a8b75080df37",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0]\ttrain-mlogloss:1.03986\teval-mlogloss:1.04835\n",
            "[1]\ttrain-mlogloss:0.98210\teval-mlogloss:0.98818\n",
            "[2]\ttrain-mlogloss:0.92883\teval-mlogloss:0.94899\n",
            "[3]\ttrain-mlogloss:0.87974\teval-mlogloss:0.90293\n",
            "[4]\ttrain-mlogloss:0.83372\teval-mlogloss:0.85867\n",
            "[5]\ttrain-mlogloss:0.78994\teval-mlogloss:0.81580\n",
            "[6]\ttrain-mlogloss:0.74976\teval-mlogloss:0.77636\n",
            "[7]\ttrain-mlogloss:0.71277\teval-mlogloss:0.74347\n",
            "[8]\ttrain-mlogloss:0.67703\teval-mlogloss:0.70950\n",
            "[9]\ttrain-mlogloss:0.64517\teval-mlogloss:0.67966\n",
            "[10]\ttrain-mlogloss:0.61358\teval-mlogloss:0.65029\n",
            "[11]\ttrain-mlogloss:0.58424\teval-mlogloss:0.62528\n",
            "[12]\ttrain-mlogloss:0.55623\teval-mlogloss:0.59629\n",
            "[13]\ttrain-mlogloss:0.53114\teval-mlogloss:0.57299\n",
            "[14]\ttrain-mlogloss:0.50635\teval-mlogloss:0.54809\n",
            "[15]\ttrain-mlogloss:0.48273\teval-mlogloss:0.52492\n",
            "[16]\ttrain-mlogloss:0.46105\teval-mlogloss:0.50573\n",
            "[17]\ttrain-mlogloss:0.44069\teval-mlogloss:0.48713\n",
            "[18]\ttrain-mlogloss:0.42144\teval-mlogloss:0.46914\n",
            "[19]\ttrain-mlogloss:0.40258\teval-mlogloss:0.44887\n",
            "[20]\ttrain-mlogloss:0.38514\teval-mlogloss:0.43199\n",
            "[21]\ttrain-mlogloss:0.36790\teval-mlogloss:0.41609\n",
            "[22]\ttrain-mlogloss:0.35201\teval-mlogloss:0.40452\n",
            "[23]\ttrain-mlogloss:0.33639\teval-mlogloss:0.38940\n",
            "[24]\ttrain-mlogloss:0.32243\teval-mlogloss:0.37671\n",
            "[25]\ttrain-mlogloss:0.30907\teval-mlogloss:0.36378\n",
            "[26]\ttrain-mlogloss:0.29570\teval-mlogloss:0.35104\n",
            "[27]\ttrain-mlogloss:0.28282\teval-mlogloss:0.33898\n",
            "[28]\ttrain-mlogloss:0.27134\teval-mlogloss:0.32693\n",
            "[29]\ttrain-mlogloss:0.26019\teval-mlogloss:0.31492\n",
            "[30]\ttrain-mlogloss:0.25017\teval-mlogloss:0.30602\n",
            "[31]\ttrain-mlogloss:0.24038\teval-mlogloss:0.29584\n",
            "[32]\ttrain-mlogloss:0.23057\teval-mlogloss:0.28589\n",
            "[33]\ttrain-mlogloss:0.22123\teval-mlogloss:0.27749\n",
            "[34]\ttrain-mlogloss:0.21278\teval-mlogloss:0.26931\n",
            "[35]\ttrain-mlogloss:0.20454\teval-mlogloss:0.26285\n",
            "[36]\ttrain-mlogloss:0.19632\teval-mlogloss:0.25432\n",
            "[37]\ttrain-mlogloss:0.18875\teval-mlogloss:0.24713\n",
            "[38]\ttrain-mlogloss:0.18158\teval-mlogloss:0.24075\n",
            "[39]\ttrain-mlogloss:0.17453\teval-mlogloss:0.23454\n",
            "[40]\ttrain-mlogloss:0.16776\teval-mlogloss:0.22759\n",
            "[41]\ttrain-mlogloss:0.16171\teval-mlogloss:0.22327\n",
            "[42]\ttrain-mlogloss:0.15550\teval-mlogloss:0.21639\n",
            "[43]\ttrain-mlogloss:0.15004\teval-mlogloss:0.21163\n",
            "[44]\ttrain-mlogloss:0.14496\teval-mlogloss:0.20701\n",
            "[45]\ttrain-mlogloss:0.13957\teval-mlogloss:0.20190\n",
            "[46]\ttrain-mlogloss:0.13483\teval-mlogloss:0.19819\n",
            "[47]\ttrain-mlogloss:0.13020\teval-mlogloss:0.19408\n",
            "[48]\ttrain-mlogloss:0.12582\teval-mlogloss:0.19061\n",
            "[49]\ttrain-mlogloss:0.12139\teval-mlogloss:0.18625\n",
            "[50]\ttrain-mlogloss:0.11737\teval-mlogloss:0.18273\n",
            "[51]\ttrain-mlogloss:0.11354\teval-mlogloss:0.17938\n",
            "[52]\ttrain-mlogloss:0.11014\teval-mlogloss:0.17714\n",
            "[53]\ttrain-mlogloss:0.10675\teval-mlogloss:0.17475\n",
            "[54]\ttrain-mlogloss:0.10361\teval-mlogloss:0.17240\n",
            "[55]\ttrain-mlogloss:0.10047\teval-mlogloss:0.16914\n",
            "[56]\ttrain-mlogloss:0.09718\teval-mlogloss:0.16611\n",
            "[57]\ttrain-mlogloss:0.09441\teval-mlogloss:0.16374\n",
            "[58]\ttrain-mlogloss:0.09151\teval-mlogloss:0.16123\n",
            "[59]\ttrain-mlogloss:0.08870\teval-mlogloss:0.15964\n",
            "[60]\ttrain-mlogloss:0.08619\teval-mlogloss:0.15687\n",
            "[61]\ttrain-mlogloss:0.08356\teval-mlogloss:0.15446\n",
            "[62]\ttrain-mlogloss:0.08114\teval-mlogloss:0.15210\n",
            "[63]\ttrain-mlogloss:0.07880\teval-mlogloss:0.14879\n",
            "[64]\ttrain-mlogloss:0.07657\teval-mlogloss:0.14714\n",
            "[65]\ttrain-mlogloss:0.07432\teval-mlogloss:0.14611\n",
            "[66]\ttrain-mlogloss:0.07218\teval-mlogloss:0.14545\n",
            "[67]\ttrain-mlogloss:0.07014\teval-mlogloss:0.14321\n",
            "[68]\ttrain-mlogloss:0.06830\teval-mlogloss:0.14105\n",
            "[69]\ttrain-mlogloss:0.06661\teval-mlogloss:0.13937\n",
            "[70]\ttrain-mlogloss:0.06486\teval-mlogloss:0.13751\n",
            "[71]\ttrain-mlogloss:0.06303\teval-mlogloss:0.13578\n",
            "[72]\ttrain-mlogloss:0.06142\teval-mlogloss:0.13390\n",
            "[73]\ttrain-mlogloss:0.05988\teval-mlogloss:0.13321\n",
            "[74]\ttrain-mlogloss:0.05848\teval-mlogloss:0.13100\n",
            "[75]\ttrain-mlogloss:0.05704\teval-mlogloss:0.13089\n",
            "[76]\ttrain-mlogloss:0.05557\teval-mlogloss:0.12939\n",
            "[77]\ttrain-mlogloss:0.05418\teval-mlogloss:0.12882\n",
            "[78]\ttrain-mlogloss:0.05278\teval-mlogloss:0.12881\n",
            "[79]\ttrain-mlogloss:0.05164\teval-mlogloss:0.12848\n",
            "[80]\ttrain-mlogloss:0.05046\teval-mlogloss:0.12605\n",
            "[81]\ttrain-mlogloss:0.04927\teval-mlogloss:0.12510\n",
            "[82]\ttrain-mlogloss:0.04809\teval-mlogloss:0.12297\n",
            "[83]\ttrain-mlogloss:0.04711\teval-mlogloss:0.12135\n",
            "[84]\ttrain-mlogloss:0.04602\teval-mlogloss:0.12080\n",
            "[85]\ttrain-mlogloss:0.04507\teval-mlogloss:0.11956\n",
            "[86]\ttrain-mlogloss:0.04408\teval-mlogloss:0.11766\n",
            "[87]\ttrain-mlogloss:0.04307\teval-mlogloss:0.11610\n",
            "[88]\ttrain-mlogloss:0.04219\teval-mlogloss:0.11573\n",
            "[89]\ttrain-mlogloss:0.04130\teval-mlogloss:0.11582\n",
            "[90]\ttrain-mlogloss:0.04048\teval-mlogloss:0.11606\n",
            "[91]\ttrain-mlogloss:0.03966\teval-mlogloss:0.11416\n",
            "[92]\ttrain-mlogloss:0.03888\teval-mlogloss:0.11435\n",
            "[93]\ttrain-mlogloss:0.03810\teval-mlogloss:0.11282\n",
            "[94]\ttrain-mlogloss:0.03739\teval-mlogloss:0.11128\n",
            "[95]\ttrain-mlogloss:0.03670\teval-mlogloss:0.11023\n",
            "[96]\ttrain-mlogloss:0.03599\teval-mlogloss:0.10927\n",
            "[97]\ttrain-mlogloss:0.03529\teval-mlogloss:0.10859\n",
            "[98]\ttrain-mlogloss:0.03468\teval-mlogloss:0.10838\n",
            "[99]\ttrain-mlogloss:0.03402\teval-mlogloss:0.10703\n",
            "[100]\ttrain-mlogloss:0.03343\teval-mlogloss:0.10704\n",
            "[101]\ttrain-mlogloss:0.03285\teval-mlogloss:0.10688\n",
            "[102]\ttrain-mlogloss:0.03230\teval-mlogloss:0.10547\n",
            "[103]\ttrain-mlogloss:0.03178\teval-mlogloss:0.10470\n",
            "[104]\ttrain-mlogloss:0.03128\teval-mlogloss:0.10477\n",
            "[105]\ttrain-mlogloss:0.03082\teval-mlogloss:0.10346\n",
            "[106]\ttrain-mlogloss:0.03030\teval-mlogloss:0.10244\n",
            "[107]\ttrain-mlogloss:0.02982\teval-mlogloss:0.10241\n",
            "[108]\ttrain-mlogloss:0.02935\teval-mlogloss:0.10277\n",
            "[109]\ttrain-mlogloss:0.02895\teval-mlogloss:0.10185\n",
            "[110]\ttrain-mlogloss:0.02852\teval-mlogloss:0.10194\n",
            "[111]\ttrain-mlogloss:0.02811\teval-mlogloss:0.10166\n",
            "[112]\ttrain-mlogloss:0.02770\teval-mlogloss:0.10178\n",
            "[113]\ttrain-mlogloss:0.02735\teval-mlogloss:0.10208\n",
            "[114]\ttrain-mlogloss:0.02696\teval-mlogloss:0.10236\n",
            "[115]\ttrain-mlogloss:0.02658\teval-mlogloss:0.10163\n",
            "[116]\ttrain-mlogloss:0.02621\teval-mlogloss:0.10187\n",
            "[117]\ttrain-mlogloss:0.02585\teval-mlogloss:0.10217\n",
            "[118]\ttrain-mlogloss:0.02548\teval-mlogloss:0.10249\n",
            "[119]\ttrain-mlogloss:0.02517\teval-mlogloss:0.10260\n",
            "[120]\ttrain-mlogloss:0.02484\teval-mlogloss:0.10204\n",
            "[121]\ttrain-mlogloss:0.02450\teval-mlogloss:0.10228\n",
            "[122]\ttrain-mlogloss:0.02418\teval-mlogloss:0.10188\n",
            "[123]\ttrain-mlogloss:0.02391\teval-mlogloss:0.10139\n",
            "[124]\ttrain-mlogloss:0.02362\teval-mlogloss:0.10090\n",
            "[125]\ttrain-mlogloss:0.02334\teval-mlogloss:0.10056\n",
            "[126]\ttrain-mlogloss:0.02306\teval-mlogloss:0.10081\n",
            "[127]\ttrain-mlogloss:0.02280\teval-mlogloss:0.10119\n",
            "[128]\ttrain-mlogloss:0.02246\teval-mlogloss:0.10085\n",
            "[129]\ttrain-mlogloss:0.02224\teval-mlogloss:0.10127\n",
            "[130]\ttrain-mlogloss:0.02198\teval-mlogloss:0.10150\n",
            "[131]\ttrain-mlogloss:0.02175\teval-mlogloss:0.10177\n",
            "[132]\ttrain-mlogloss:0.02149\teval-mlogloss:0.10134\n",
            "[133]\ttrain-mlogloss:0.02124\teval-mlogloss:0.10167\n",
            "[134]\ttrain-mlogloss:0.02103\teval-mlogloss:0.10134\n",
            "[135]\ttrain-mlogloss:0.02081\teval-mlogloss:0.10175\n",
            "[136]\ttrain-mlogloss:0.02063\teval-mlogloss:0.10091\n",
            "[137]\ttrain-mlogloss:0.02044\teval-mlogloss:0.10077\n",
            "[138]\ttrain-mlogloss:0.02022\teval-mlogloss:0.10043\n",
            "[139]\ttrain-mlogloss:0.02005\teval-mlogloss:0.09971\n",
            "[140]\ttrain-mlogloss:0.01985\teval-mlogloss:0.09946\n",
            "[141]\ttrain-mlogloss:0.01971\teval-mlogloss:0.09939\n",
            "[142]\ttrain-mlogloss:0.01960\teval-mlogloss:0.09975\n",
            "[143]\ttrain-mlogloss:0.01938\teval-mlogloss:0.10006\n",
            "[144]\ttrain-mlogloss:0.01922\teval-mlogloss:0.10035\n",
            "[145]\ttrain-mlogloss:0.01903\teval-mlogloss:0.10004\n",
            "[146]\ttrain-mlogloss:0.01890\teval-mlogloss:0.09942\n",
            "[147]\ttrain-mlogloss:0.01878\teval-mlogloss:0.09890\n",
            "[148]\ttrain-mlogloss:0.01866\teval-mlogloss:0.09840\n",
            "[149]\ttrain-mlogloss:0.01861\teval-mlogloss:0.09837\n",
            "[150]\ttrain-mlogloss:0.01855\teval-mlogloss:0.09852\n",
            "[151]\ttrain-mlogloss:0.01849\teval-mlogloss:0.09856\n",
            "[152]\ttrain-mlogloss:0.01831\teval-mlogloss:0.09818\n",
            "[153]\ttrain-mlogloss:0.01831\teval-mlogloss:0.09823\n",
            "[154]\ttrain-mlogloss:0.01826\teval-mlogloss:0.09843\n",
            "[155]\ttrain-mlogloss:0.01820\teval-mlogloss:0.09851\n",
            "[156]\ttrain-mlogloss:0.01808\teval-mlogloss:0.09890\n",
            "[157]\ttrain-mlogloss:0.01804\teval-mlogloss:0.09852\n",
            "[158]\ttrain-mlogloss:0.01799\teval-mlogloss:0.09849\n",
            "[159]\ttrain-mlogloss:0.01789\teval-mlogloss:0.09834\n",
            "[160]\ttrain-mlogloss:0.01785\teval-mlogloss:0.09850\n",
            "[161]\ttrain-mlogloss:0.01779\teval-mlogloss:0.09857\n",
            "[162]\ttrain-mlogloss:0.01774\teval-mlogloss:0.09874\n",
            "[163]\ttrain-mlogloss:0.01770\teval-mlogloss:0.09892\n",
            "[164]\ttrain-mlogloss:0.01765\teval-mlogloss:0.09913\n",
            "[165]\ttrain-mlogloss:0.01760\teval-mlogloss:0.09925\n",
            "[166]\ttrain-mlogloss:0.01756\teval-mlogloss:0.09942\n",
            "[167]\ttrain-mlogloss:0.01746\teval-mlogloss:0.09921\n",
            "[168]\ttrain-mlogloss:0.01741\teval-mlogloss:0.09944\n",
            "[169]\ttrain-mlogloss:0.01737\teval-mlogloss:0.09905\n",
            "[170]\ttrain-mlogloss:0.01725\teval-mlogloss:0.09860\n",
            "[171]\ttrain-mlogloss:0.01721\teval-mlogloss:0.09886\n",
            "[172]\ttrain-mlogloss:0.01718\teval-mlogloss:0.09857\n",
            "Train Accuracy: 1.0000\n",
            "Test Accuracy: 0.9583\n",
            "Train F1 Score: 1.0000\n",
            "Test F1 Score: 0.9583\n",
            "\n",
            "Confusion Matrix:\n",
            "[[8 0 0]\n",
            " [1 8 0]\n",
            " [0 0 7]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      1.00      0.94         8\n",
            "           1       1.00      0.89      0.94         9\n",
            "           2       1.00      1.00      1.00         7\n",
            "\n",
            "    accuracy                           0.96        24\n",
            "   macro avg       0.96      0.96      0.96        24\n",
            "weighted avg       0.96      0.96      0.96        24\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import xgboost as xgb\n",
        "\n",
        "new_data = pd.read_csv('https://byui-cse.github.io/cse450-course/ice/wine/data/wine-holdout.csv')\n",
        "\n",
        "if 'wine' in new_data.columns:\n",
        "    new_data = new_data.drop(columns=['wine'])\n",
        "\n",
        "X_new = new_data\n",
        "dholdout = xgb.DMatrix(new_data)\n",
        "\n",
        "# Predict using the trained model\n",
        "y_pred_holdout = model.predict(dholdout)\n",
        "\n",
        "# Save predictions as a single-column CSV with header 'wine'\n",
        "results = pd.DataFrame({'wine': y_pred_holdout.astype(int)})  # Convert to int for classification labels\n",
        "results.to_csv(\"JasonRao-ice1-predictions.csv\", index=False)\n",
        "\n",
        "print(\"Predictions saved to JasonRao-ice1-predictions.csv\")"
      ],
      "metadata": {
        "id": "HdOvQR1UgHWu",
        "outputId": "6e11dc96-554d-4195-b0da-5440e54bb0e7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions saved to JasonRao-ice1-predictions.csv\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "hint_xgboost.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5"
    },
    "vscode": {
      "interpreter": {
        "hash": "011be37f879e0ba7a3d94f28c1e9a24aca4c9c0e96be9163ce8dabdf859b445e"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}